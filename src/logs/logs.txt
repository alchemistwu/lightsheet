0: train_loss=0.5629545719829161, val_loss=0.6876630094789323, train_acc=0.8309130072593689, val_acc=0.7364435195922852
1: train_loss=0.4237527934758277, val_loss=0.811133032753354, train_acc=0.8839162588119507, val_acc=0.7625986933708191
2: train_loss=0.36929288267548255, val_loss=0.5456547818723179, train_acc=0.8983234763145447, val_acc=0.8156893849372864
3: train_loss=0.3277981090563689, val_loss=0.6906125580980664, train_acc=0.9062316417694092, val_acc=0.7536917924880981
4: train_loss=0.3022772523260333, val_loss=0.8197520432018098, train_acc=0.912997841835022, val_acc=0.7053322792053223
5: train_loss=0.2833358323519962, val_loss=0.5191819596858251, train_acc=0.9154459238052368, val_acc=0.8575780391693115
6: train_loss=0.2667910923755836, val_loss=0.5057927941282591, train_acc=0.9189603328704834, val_acc=0.8232437372207642
7: train_loss=0.24847280244242947, val_loss=1.4680563012758892, train_acc=0.9228566884994507, val_acc=0.509236752986908
8: train_loss=0.24054381357288937, val_loss=0.4279505541282041, train_acc=0.9242483377456665, val_acc=0.8598731756210327
9: train_loss=0.22653902758267933, val_loss=0.3110881146220934, train_acc=0.9282020926475525, val_acc=0.8959807753562927
10: train_loss=0.221231375425017, val_loss=0.2595606934988782, train_acc=0.9285518527030945, val_acc=0.9166423678398132
11: train_loss=0.2046170877616813, val_loss=0.3594936084534441, train_acc=0.9329822659492493, val_acc=0.8810970783233643
12: train_loss=0.2020341149346731, val_loss=0.519848665311223, train_acc=0.9337443113327026, val_acc=0.8342626690864563
13: train_loss=0.2017824905227064, val_loss=0.47191574921210605, train_acc=0.9330183267593384, val_acc=0.8420411348342896
14: train_loss=0.18326248104561477, val_loss=0.2933522557751054, train_acc=0.9393552541732788, val_acc=0.9059001207351685
15: train_loss=0.1825464694407091, val_loss=0.285768457289253, train_acc=0.9383712410926819, val_acc=0.9098051190376282
16: train_loss=0.17662918946385925, val_loss=0.3847071927573, train_acc=0.9388806819915771, val_acc=0.878684937953949
17: train_loss=0.17487928523779275, val_loss=0.3328166011543501, train_acc=0.9396159052848816, val_acc=0.9024409055709839
18: train_loss=0.16243130555897725, val_loss=0.28267770029959227, train_acc=0.9439535737037659, val_acc=0.9090096950531006
19: train_loss=0.15642534709238248, val_loss=0.26663777675657047, train_acc=0.9454169869422913, val_acc=0.9181267023086548
20: train_loss=0.14921162650552713, val_loss=0.24968193214209305, train_acc=0.9492267370223999, val_acc=0.9255917072296143
21: train_loss=0.1460799097609051, val_loss=0.43008147543739705, train_acc=0.9485412836074829, val_acc=0.8708889484405518
22: train_loss=0.15739587532094315, val_loss=0.33369969399202437, train_acc=0.9442300200462341, val_acc=0.9067959785461426
23: train_loss=0.14784108904865254, val_loss=0.3368063982398737, train_acc=0.9474465847015381, val_acc=0.8964669704437256
24: train_loss=0.13403960856159589, val_loss=0.29227677386786255, train_acc=0.9510108828544617, val_acc=0.9164909720420837
25: train_loss=0.12888842425485242, val_loss=0.300397144098367, train_acc=0.9539238810539246, val_acc=0.912504255771637
26: train_loss=0.12811708875259725, val_loss=0.4008710966223762, train_acc=0.9531434774398804, val_acc=0.8815948963165283
27: train_loss=0.1213301432723357, val_loss=0.3018290516698644, train_acc=0.9580813646316528, val_acc=0.9087056517601013
28: train_loss=0.13081144992369206, val_loss=0.23781300336122513, train_acc=0.9545684456825256, val_acc=0.9238062500953674
29: train_loss=0.11711340824793037, val_loss=0.3876966376389776, train_acc=0.959348738193512, val_acc=0.8872511982917786
30: train_loss=0.11298753343714167, val_loss=0.23660694621503353, train_acc=0.9590330123901367, val_acc=0.9256375432014465
31: train_loss=0.11557201061640132, val_loss=0.43366309805285363, train_acc=0.9582754373550415, val_acc=0.8731393218040466
32: train_loss=0.11000873933513838, val_loss=0.23594309850817635, train_acc=0.9608665704727173, val_acc=0.9210841059684753
33: train_loss=0.10596156310791688, val_loss=0.22461458011752083, train_acc=0.9627137184143066, val_acc=0.9375935196876526
34: train_loss=0.10786073193878341, val_loss=0.22522480688279584, train_acc=0.9617601037025452, val_acc=0.9329593181610107
35: train_loss=0.11186648513022782, val_loss=0.3284950178293955, train_acc=0.9598382711410522, val_acc=0.9164743423461914
36: train_loss=0.10648558515373409, val_loss=0.2691259093227841, train_acc=0.9616995453834534, val_acc=0.916820228099823
37: train_loss=0.10849949459400192, val_loss=0.3632027965393804, train_acc=0.9646415114402771, val_acc=0.9067135453224182
38: train_loss=0.10341415027334001, val_loss=0.34270032371083897, train_acc=0.9624795317649841, val_acc=0.9095202684402466
39: train_loss=0.09414104699705264, val_loss=0.35467279941907953, train_acc=0.9657357931137085, val_acc=0.8934532999992371
40: train_loss=0.08593110417251147, val_loss=0.7711294840666509, train_acc=0.9696719646453857, val_acc=0.7809001207351685
41: train_loss=0.08700746676564758, val_loss=0.3680424223698321, train_acc=0.9685127139091492, val_acc=0.9118030667304993
42: train_loss=0.09783420979458157, val_loss=0.2663084228656122, train_acc=0.9638809561729431, val_acc=0.9207380414009094
43: train_loss=0.10089007858609648, val_loss=0.34298361908821834, train_acc=0.96396803855896, val_acc=0.9084654450416565
44: train_loss=0.09833434461961175, val_loss=0.25927504515718847, train_acc=0.9654498100280762, val_acc=0.9217231273651123
45: train_loss=0.08483212340888024, val_loss=0.278538961495672, train_acc=0.9707303047180176, val_acc=0.9215542674064636
46: train_loss=0.07833089943800499, val_loss=0.25761902811271803, train_acc=0.9713615775108337, val_acc=0.9265384078025818
47: train_loss=0.07575202255359036, val_loss=0.23636440542482196, train_acc=0.9727297425270081, val_acc=0.9333277344703674
48: train_loss=0.07685095616214756, val_loss=0.2637334940511556, train_acc=0.9716945290565491, val_acc=0.9178040027618408
49: train_loss=0.0826604838360456, val_loss=0.3005763263929458, train_acc=0.9710334539413452, val_acc=0.9185779094696045
50: train_loss=0.0883145729663152, val_loss=0.2844972047245219, train_acc=0.9690837264060974, val_acc=0.9229533076286316
51: train_loss=0.07211432809435654, val_loss=0.26706263946280595, train_acc=0.9738744497299194, val_acc=0.9226997494697571
52: train_loss=0.08280746309078227, val_loss=0.35455942570808385, train_acc=0.9706335663795471, val_acc=0.9042897820472717
53: train_loss=0.07202429748767263, val_loss=0.3146649009237687, train_acc=0.9735850691795349, val_acc=0.9157966375350952
54: train_loss=0.07349756282279422, val_loss=0.3083019355045898, train_acc=0.972564697265625, val_acc=0.9210670590400696
55: train_loss=0.0721236456371562, val_loss=0.35067448685211794, train_acc=0.9729903340339661, val_acc=0.9114943146705627
56: train_loss=0.06862286022341559, val_loss=0.36961096933200244, train_acc=0.9753415584564209, val_acc=0.9088089466094971
57: train_loss=0.0660995668231449, val_loss=0.35569435189522447, train_acc=0.9754781126976013, val_acc=0.9164255261421204
58: train_loss=0.06446810962798556, val_loss=0.2880735170273554, train_acc=0.9766306281089783, val_acc=0.9301838874816895
59: train_loss=0.07079492523454682, val_loss=0.31552189118450596, train_acc=0.9741643071174622, val_acc=0.9223744869232178
60: train_loss=0.07089361321299412, val_loss=0.2685576923901126, train_acc=0.975204586982727, val_acc=0.9309000372886658
61: train_loss=0.06161857853994427, val_loss=0.30708177467542036, train_acc=0.9775248169898987, val_acc=0.926173746585846
62: train_loss=0.06517469263022678, val_loss=0.2988608226712261, train_acc=0.9764792919158936, val_acc=0.9279900193214417
63: train_loss=0.06115025839854297, val_loss=0.3213700443683636, train_acc=0.9773494601249695, val_acc=0.9266615509986877
64: train_loss=0.058453540533285095, val_loss=0.2673326622517336, train_acc=0.9789913892745972, val_acc=0.934352695941925
65: train_loss=0.05824059400138264, val_loss=0.2929881141476688, train_acc=0.9789416790008545, val_acc=0.925361692905426
66: train_loss=0.05961267994759032, val_loss=0.46394358122987406, train_acc=0.9789224863052368, val_acc=0.8892226815223694
67: train_loss=0.06218975790566377, val_loss=0.2584023233503103, train_acc=0.9781423807144165, val_acc=0.9365642666816711
68: train_loss=0.05456405267705535, val_loss=0.3279735600309713, train_acc=0.9805337190628052, val_acc=0.9234165549278259
69: train_loss=0.05801301310332027, val_loss=0.3979295383074454, train_acc=0.9789636731147766, val_acc=0.9063198566436768
70: train_loss=0.055246064701482495, val_loss=0.5301980023227987, train_acc=0.9801170825958252, val_acc=0.909267008304596
71: train_loss=0.052418540715156815, val_loss=0.31158230347292765, train_acc=0.9813628196716309, val_acc=0.9291954040527344
72: train_loss=0.05467845307896971, val_loss=0.31199058668599244, train_acc=0.9803212881088257, val_acc=0.9267426133155823
73: train_loss=0.05584736254049321, val_loss=0.3657894814830451, train_acc=0.9796056747436523, val_acc=0.9237642884254456
74: train_loss=0.06302994821902573, val_loss=0.2879594334711631, train_acc=0.9782834649085999, val_acc=0.9308239221572876
75: train_loss=0.05646699684448033, val_loss=0.29140023550107363, train_acc=0.9794818162918091, val_acc=0.9318170547485352
76: train_loss=0.05762444727359489, val_loss=0.4078462378432353, train_acc=0.9800979495048523, val_acc=0.9155899882316589
77: train_loss=0.05513579033754777, val_loss=0.33203877153850736, train_acc=0.9819328188896179, val_acc=0.9264915585517883
78: train_loss=0.050932983049218304, val_loss=0.3178339935839176, train_acc=0.9820797443389893, val_acc=0.9282991290092468
79: train_loss=0.049771890066755704, val_loss=0.3641159879487185, train_acc=0.9822009801864624, val_acc=0.9183512926101685
80: train_loss=0.04879108684788403, val_loss=0.24366946225719793, train_acc=0.982783317565918, val_acc=0.9393491148948669
81: train_loss=0.049720029263516236, val_loss=0.39881706131356104, train_acc=0.9822382926940918, val_acc=0.9159454107284546
82: train_loss=0.04792191744774986, val_loss=0.5812094636438858, train_acc=0.9834843277931213, val_acc=0.9030004739761353
83: train_loss=0.054228513266288206, val_loss=0.38397935910948683, train_acc=0.9812430143356323, val_acc=0.9179681539535522
84: train_loss=0.04689636000864625, val_loss=0.3526926591016707, train_acc=0.9830650687217712, val_acc=0.9212715029716492
85: train_loss=0.052058767718960404, val_loss=0.4561290537849778, train_acc=0.9812659025192261, val_acc=0.9109938144683838
86: train_loss=0.050427617668632116, val_loss=0.3737200352230242, train_acc=0.981786847114563, val_acc=0.9193416237831116
87: train_loss=0.04422221118626544, val_loss=0.26967143010170685, train_acc=0.9849135279655457, val_acc=0.9318960905075073
88: train_loss=0.045951869862883965, val_loss=0.32516533384720486, train_acc=0.9836175441741943, val_acc=0.9276524186134338
89: train_loss=0.04463260983216961, val_loss=0.32161624099881875, train_acc=0.9842653274536133, val_acc=0.926231861114502
90: train_loss=0.044275389891258704, val_loss=0.32945767222415834, train_acc=0.9841140508651733, val_acc=0.9255304336547852
91: train_loss=0.044597645539581864, val_loss=0.3657535030728295, train_acc=0.9848707914352417, val_acc=0.9245121479034424
92: train_loss=0.04352269461448903, val_loss=0.3250855803933172, train_acc=0.9846039414405823, val_acc=0.9282994866371155
93: train_loss=0.04336654651859344, val_loss=0.3402128650673798, train_acc=0.9846132397651672, val_acc=0.9283022880554199
94: train_loss=0.043213064324409446, val_loss=0.3437137214378232, train_acc=0.9846817851066589, val_acc=0.9269145131111145
95: train_loss=0.04702373547268166, val_loss=0.28974875319926513, train_acc=0.9838742017745972, val_acc=0.9305463433265686
96: train_loss=0.04186060816703333, val_loss=0.31766634097411517, train_acc=0.9852840900421143, val_acc=0.9261983633041382
97: train_loss=0.04460950945074277, val_loss=0.40983618210468975, train_acc=0.9842410683631897, val_acc=0.9164139032363892
98: train_loss=0.041490857268200336, val_loss=0.3300270876359372, train_acc=0.9859070181846619, val_acc=0.9278510808944702
99: train_loss=0.042772610653501776, val_loss=0.40334829550591256, train_acc=0.9847383499145508, val_acc=0.912234365940094
